{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzTF-EswgYEx"
      },
      "outputs": [],
      "source": [
        "# kill old stuff\n",
        "!pkill -f \"uvicorn.*8000\" || true\n",
        "!fuser -k 8000/tcp || true\n",
        "!pkill -f \"cloudflared tunnel\" || true"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kokoro>=0.9.2 soundfile\n",
        "!apt-get -qq -y install espeak-ng > /dev/null 2>&1\n",
        "!pip -q install \"fastapi[standard]\" uvicorn soundfile nump\n",
        "!pip -q install scipy\n",
        "\n",
        "from kokoro import KPipeline\n",
        "from IPython.display import display, Audio\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import asyncio\n",
        "import websockets\n",
        "import io, base64, json\n",
        "from typing import Optional\n",
        "import numpy as np\n",
        "from fastapi import FastAPI, WebSocket, WebSocketDisconnect\n",
        "from fastapi.responses import HTMLResponse\n",
        "import uvicorn"
      ],
      "metadata": {
        "id": "hzLdChVHg3Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UI = r\"\"\"<!doctype html>\n",
        "<meta charset=\"utf-8\" />\n",
        "<title>TTS (spec-compliant)</title>\n",
        "<style>\n",
        "  body{font:14px/1.4 system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif;margin:24px}\n",
        "  .row{margin-bottom:10px}\n",
        "  input[type=text]{width:520px}\n",
        "  textarea{width:520px;height:100px}\n",
        "  #caps{\n",
        "    white-space: pre-wrap;     /* keep quotes/brackets visible */\n",
        "    overflow-wrap: anywhere;   /* wrap long JSON tokens */\n",
        "    word-break: break-word;    /* legacy alias; fine to keep */\n",
        "    background:#f6f6f6; padding:8px; border-radius:8px; min-height:3em;\n",
        "    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;\n",
        "  }\n",
        "  #status{margin-left:8px;color:#555}\n",
        "</style>\n",
        "\n",
        "<h2>TTS WebSocket Client</h2>\n",
        "<div class=\"row\">\n",
        "  <input id=\"url\" type=\"text\" placeholder=\"ws(s)://host/ws\" />\n",
        "  <button id=\"connect\">Connect</button>\n",
        "  <button id=\"speak\">Speak</button>\n",
        "\n",
        "  <label style=\"margin-left:12px\">\n",
        "    Words/chunk:\n",
        "    <input id=\"wpc\" type=\"number\" min=\"1\" value=\"3\" style=\"width:60px\">\n",
        "  </label>\n",
        "  <button id=\"speakChunked\">Speak (chunked)</button>\n",
        "  <button id=\"speakPunct\">Speak (punct-only)</button>\n",
        "\n",
        "  <button id=\"end\">End</button>\n",
        "  <span id=\"status\">[disconnected]</span>\n",
        "</div>\n",
        "\n",
        "<div class=\"row\">\n",
        "  <textarea id=\"text\" rows=\"3\" cols=\"70\" placeholder=\"Type text here...\"></textarea>\n",
        "</div>\n",
        "\n",
        "<h3>Captions</h3>\n",
        "<div id=\"caps\"></div>\n",
        "\n",
        "<script>\n",
        "\"use strict\";\n",
        "\n",
        "let ws, ctx;\n",
        "let playhead = 0;\n",
        "\n",
        "// punctuation boundaries (English + common CJK)\n",
        "const PUNCT_RE = /[.!?;:,â€¦ï¼Œã€‚ï¼Ÿï¼ï¼›ï¼šã€]/;\n",
        "\n",
        "const $ = id => document.getElementById(id);\n",
        "\n",
        "function relWsURL(){\n",
        "  const p = location.protocol === \"https:\" ? \"wss\" : \"ws\";\n",
        "  return p + \"://\" + location.host + \"/ws\";\n",
        "}\n",
        "\n",
        "window.addEventListener(\"DOMContentLoaded\", () => {\n",
        "  const u = $(\"url\");\n",
        "  if (u && !u.value) u.value = relWsURL();\n",
        "});\n",
        "\n",
        "async function ensureAudio(){\n",
        "  if (!ctx) ctx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 44100 });\n",
        "  if (ctx.state === \"suspended\") await ctx.resume();\n",
        "  if (playhead === 0) playhead = ctx.currentTime;\n",
        "}\n",
        "\n",
        "// trim leading/trailing near-silence on Int16 PCM\n",
        "function trimPCM16(pcm, thresh = 3) {\n",
        "  let s = 0, e = pcm.length - 1;\n",
        "  while (s < pcm.length && Math.abs(pcm[s]) <= thresh) s++;\n",
        "  while (e >= s && Math.abs(pcm[e]) <= thresh) e--;\n",
        "  return s > e ? new Int16Array(0) : pcm.subarray(s, e + 1);\n",
        "}\n",
        "\n",
        "function playPcm16Mono44100(b64){\n",
        "  if (!ctx) ctx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 44100 });\n",
        "  if (playhead === 0) playhead = ctx.currentTime;\n",
        "\n",
        "  // decode base64 -> Int16\n",
        "  const bytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n",
        "  const view  = new DataView(bytes.buffer);\n",
        "  const N = bytes.byteLength >> 1;\n",
        "  const pcm = new Int16Array(N);\n",
        "  for (let i = 0; i < N; i++) pcm[i] = view.getInt16(i*2, true);\n",
        "\n",
        "  // trim head/tail near-silence\n",
        "  const trimmed = trimPCM16(pcm);\n",
        "  if (trimmed.length === 0) return;\n",
        "\n",
        "  // Int16 -> Float32\n",
        "  const f32 = new Float32Array(trimmed.length);\n",
        "  for (let i = 0; i < trimmed.length; i++) {\n",
        "    f32[i] = Math.max(-1, Math.min(1, trimmed[i] / 32767));\n",
        "  }\n",
        "\n",
        "  // make AudioBuffer\n",
        "  const buf = ctx.createBuffer(1, f32.length, 44100);\n",
        "  buf.copyToChannel(f32, 0, 0);\n",
        "\n",
        "  // schedule sequential playback with a tight guard (3ms)\n",
        "  const now = ctx.currentTime;\n",
        "  if (playhead < now) playhead = now;\n",
        "  const startAt = Math.max(playhead, now + 0.003);\n",
        "  const endAt   = startAt + buf.duration;\n",
        "\n",
        "  // tiny fades to avoid clicks\n",
        "  const gn = ctx.createGain();\n",
        "  gn.gain.setValueAtTime(0, startAt);\n",
        "  gn.gain.linearRampToValueAtTime(1, startAt + 0.005);\n",
        "  gn.gain.setValueAtTime(1, endAt - 0.005);\n",
        "  gn.gain.linearRampToValueAtTime(0, endAt);\n",
        "\n",
        "  const src = ctx.createBufferSource();\n",
        "  src.buffer = buf;\n",
        "  src.connect(gn);\n",
        "  gn.connect(ctx.destination);\n",
        "  src.start(startAt);\n",
        "\n",
        "  playhead = endAt;\n",
        "}\n",
        "\n",
        "// Grapheme-aware splitter (handles emoji/accents). Falls back to Array.from.\n",
        "const GRAPHEME_SEG = (window.Intl && Intl.Segmenter)\n",
        "  ? new Intl.Segmenter(undefined, { granularity: \"grapheme\" })\n",
        "  : null;\n",
        "\n",
        "function splitGraphemes(str) {\n",
        "  if (GRAPHEME_SEG) return Array.from(GRAPHEME_SEG.segment(str), s => s.segment);\n",
        "  return Array.from(str);\n",
        "}\n",
        "\n",
        "// ONLY split at punctuation (no word-count fallback)\n",
        "function chunkByPunctOnly(text, punctRe = PUNCT_RE) {\n",
        "  const tokens = String(text).trim().split(/\\s+/);\n",
        "  const chunks = [];\n",
        "  let cur = [];\n",
        "  for (const tk of tokens) {\n",
        "    cur.push(tk);\n",
        "    if (punctRe.test(tk.slice(-1))) {\n",
        "      chunks.push(cur.join(\" \") + \" \");\n",
        "      cur = [];\n",
        "    }\n",
        "  }\n",
        "  if (cur.length) chunks.push(cur.join(\" \") + \" \");\n",
        "  return chunks;\n",
        "}\n",
        "\n",
        "const sleep = ms => new Promise(r => setTimeout(r, ms));\n",
        "function setStatus(s){ $(\"status\").textContent = s; }\n",
        "\n",
        "// Connect\n",
        "$(\"connect\").onclick = async () => {\n",
        "  await ensureAudio();\n",
        "  playhead = ctx.currentTime;\n",
        "\n",
        "  if (ws) { try { ws.close(); } catch {} }\n",
        "  const url = $(\"url\").value.trim();\n",
        "\n",
        "  // simple validation without regex (prevents the regex error)\n",
        "  try { new URL(url); } catch { alert(\"Invalid URL\"); return; }\n",
        "  const okScheme = url.startsWith(\"ws://\") || url.startsWith(\"wss://\");\n",
        "  const okPath   = url.endsWith(\"/ws\");\n",
        "  if (!okScheme || !okPath) { alert(\"URL must start with ws:// or wss:// and end with /ws\"); return; }\n",
        "\n",
        "  ws = new WebSocket(url);\n",
        "  ws.onopen = () => {\n",
        "    setStatus(\"[connected]\");\n",
        "    ws.send(JSON.stringify({ text: \" \", flush: false })); // prime\n",
        "  };\n",
        "  ws.onclose = () => setStatus(\"[disconnected]\");\n",
        "  ws.onerror = e => { setStatus(\"[error]\"); console.error(\"ws error\", e); };\n",
        "  ws.onmessage = (e) => {\n",
        "  let m; try { m = JSON.parse(e.data); } catch { return; }\n",
        "\n",
        "  // play audio if present\n",
        "  if (typeof m.audio === \"string\" && m.audio) {\n",
        "    playPcm16Mono44100(m.audio);\n",
        "  }\n",
        "\n",
        "  if (m.alignment !== undefined) {\n",
        "  $(\"caps\").textContent = (typeof m.alignment === \"string\")\n",
        "    ? m.alignment\n",
        "    : JSON.stringify(m.alignment);  // no pretty-printing\n",
        "  }\n",
        "};\n",
        "\n",
        "};\n",
        "\n",
        "// Speak (single flush)\n",
        "$(\"speak\").onclick = async () => {\n",
        "  if (!ws || ws.readyState !== 1) return alert(\"Connect first\");\n",
        "  await ensureAudio();\n",
        "  playhead = Math.max(playhead, ctx.currentTime);\n",
        "\n",
        "  const text = $(\"text\").value.trim();\n",
        "  if (!text) return;\n",
        "\n",
        "  ws.send(JSON.stringify({ text, flush: true }));\n",
        "};\n",
        "\n",
        "// Speak (chunked by N words)\n",
        "$(\"speakChunked\").onclick = async () => {\n",
        "  if (!ws || ws.readyState !== 1) return alert(\"Connect first\");\n",
        "  await ensureAudio();\n",
        "  playhead = Math.max(playhead, ctx.currentTime);\n",
        "\n",
        "  const text = $(\"text\").value.trim();\n",
        "  if (!text) return;\n",
        "\n",
        "  const N = Math.max(1, parseInt($(\"wpc\").value || \"1\", 10));\n",
        "  const words = text.split(/\\s+/);\n",
        "\n",
        "  ws.send(JSON.stringify({ text: \" \", flush: false })); // prime\n",
        "\n",
        "  for (let i = 0; i < words.length; i += N) {\n",
        "    const chunk = words.slice(i, i + N).join(\" \") + \" \";\n",
        "    ws.send(JSON.stringify({ text: chunk, flush: true }));\n",
        "    // await sleep(10); // optional tiny throttle\n",
        "  }\n",
        "  ws.send(JSON.stringify({ text: \"\", flush: false })); // end\n",
        "};\n",
        "\n",
        "// Speak (punctuation-only)\n",
        "$(\"speakPunct\").onclick = async () => {\n",
        "  if (!ws || ws.readyState !== 1) return alert(\"Connect first\");\n",
        "  await ensureAudio();\n",
        "  playhead = Math.max(playhead, ctx.currentTime);\n",
        "\n",
        "  const text = $(\"text\").value.trim();\n",
        "  if (!text) return;\n",
        "\n",
        "  const chunks = chunkByPunctOnly(text);\n",
        "\n",
        "  ws.send(JSON.stringify({ text: \" \", flush: false })); // prime\n",
        "  for (const c of chunks) {\n",
        "    ws.send(JSON.stringify({ text: c, flush: true }));\n",
        "    // await sleep(10); // optional tiny throttle\n",
        "  }\n",
        "  ws.send(JSON.stringify({ text: \"\", flush: false }));  // end\n",
        "};\n",
        "\n",
        "// End\n",
        "$(\"end\").onclick = () => {\n",
        "  if (ws && ws.readyState === 1) {\n",
        "    try { ws.send(JSON.stringify({ text: \"\", flush: false })); } catch {}\n",
        "    try { ws.close(); } catch {}\n",
        "  }\n",
        "  if (ctx) playhead = ctx.currentTime;\n",
        "};\n",
        "</script>\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "IzDzNvGsg4gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Spec helpers: tensorâ†’numpy, resample to 44.1 kHz, PCM16 bytes, alignment ===\n",
        "import base64, json, numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    TORCH = True\n",
        "except Exception:\n",
        "    TORCH = False\n",
        "\n",
        "\n",
        "SRC_SR_DEFAULT = 24000   # model's native sample rate\n",
        "DST_SR = 44100           # spec requires 44.1k mono PCM16\n",
        "\n",
        "def to_numpy_audio(x):\n",
        "    import torch\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        x = x.detach().to(\"cpu\").float().numpy()\n",
        "    else:\n",
        "        x = np.asarray(x, dtype=np.float32)\n",
        "    if x.ndim == 2:          # downmix\n",
        "        x = x.mean(axis=-1)\n",
        "    return np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "def log_audio(tag, a):\n",
        "    x = to_numpy_audio(a)\n",
        "    rms = float(np.sqrt(np.mean(x**2))) if x.size else 0.0\n",
        "    print(f\"[{tag}] shape={x.shape} rms={rms:.6f}\")\n",
        "\n",
        "def resample_to_44k(a_f32, src_sr, dst_sr=DST_SR):\n",
        "    if a_f32.size == 0 or src_sr == dst_sr: return a_f32\n",
        "    g = np.gcd(src_sr, dst_sr); up, down = dst_sr // g, src_sr // g\n",
        "    return signal.resample_poly(a_f32, up, down).astype(np.float32, copy=False)\n",
        "\n",
        "def encode_chunk_base64_pcm16_44k(audio, src_sr, min_ms=100):\n",
        "    \"\"\"\n",
        "    Returns (base64_pcm16, n_samples_44k). Ensures >= min_ms of audio so the browser plays it.\n",
        "    \"\"\"\n",
        "    a = resample_to_44k(to_numpy_audio(audio), src_sr, DST_SR)\n",
        "    min_samples = int(DST_SR * (min_ms / 1000.0))\n",
        "    if a.size < min_samples:\n",
        "        a = np.pad(a, (0, min_samples - a.size))\n",
        "    a = np.clip(a, -1.0, 1.0)\n",
        "    pcm16 = (a * 32767.0).astype(np.int16, copy=False)\n",
        "    b64 = base64.b64encode(pcm16.tobytes()).decode(\"ascii\")\n",
        "    return b64, int(a.size)\n",
        "\n",
        "def total_ms_from_samples(n44):  # 44.1k only\n",
        "    return 1000.0 * n44 / float(DST_SR)\n",
        "\n",
        "# alignment\n",
        "def _char_weight(ch):\n",
        "    if ch.isspace(): return 0.45\n",
        "    if ch in \".!?\": return 0.40\n",
        "    if ch in \",;:\": return 0.55\n",
        "    if ch.lower() in \"aeiou\": return 1.15\n",
        "    return 1.0\n",
        "\n",
        "def build_alignment_from_gs(gs, total_ms):\n",
        "\n",
        "    chars = list(gs or \"\")\n",
        "    if not chars: return {\"chars\": [], \"char_start_times_ms\": [], \"char_durations_ms\": []}\n",
        "    w = np.array([_char_weight(c) for c in chars], float); s = w.sum() or 1.0\n",
        "    d = w / s * float(total_ms)\n",
        "    di = np.floor(d).astype(int); diff = int(round(total_ms)) - int(di.sum())\n",
        "    if diff: di[-1] += diff\n",
        "    MIN=20; need = np.maximum(0, MIN - di);\n",
        "    if need.any(): di += need; di[-1] -= int(need.sum()); di[-1] = max(1, di[-1])\n",
        "    starts = np.concatenate(([0], np.cumsum(di[:-1]))).astype(int).tolist()\n",
        "    return {\"chars\": chars, \"char_start_times_ms\": starts, \"char_durations_ms\": di.astype(int).tolist()}\n"
      ],
      "metadata": {
        "id": "qrotYcoVg7Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import WebSocket, WebSocketDisconnect\n",
        "import time, statistics\n",
        "from time import perf_counter_ns\n",
        "import numpy as np\n",
        "import base64\n",
        "LAT = []   # collect many samples to compute p50 across utterances\n",
        "\n",
        "\n",
        "DEFAULT_LANG = \"a\"\n",
        "DEFAULT_VOICE = \"af_heart\"\n",
        "\n",
        "_pipeline = None\n",
        "_cur_lang = None\n",
        "\n",
        "def get_pipeline(lang_code: str):\n",
        "    global _pipeline, _cur_lang\n",
        "    if _pipeline is None or _cur_lang != lang_code:\n",
        "        _pipeline = KPipeline(lang_code=lang_code)   # <-- your TTS pipeline\n",
        "        _cur_lang = lang_code\n",
        "    return _pipeline\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/ui\")\n",
        "def ui():\n",
        "    return HTMLResponse(UI)\n",
        "\n",
        "@app.websocket(\"/ws\")\n",
        "async def tts_ws(ws: WebSocket):\n",
        "    \"\"\"\n",
        "    INPUT (client â†’ server): { \"text\": str, \"flush\": bool }\n",
        "      - first chunk: \" \" (single space)\n",
        "      - flush:true â†’ synthesize buffered text so far, KEEP socket open\n",
        "      - final chunk: \"\" (empty string, flush:false/omitted) â†’ CLOSE socket\n",
        "\n",
        "    OUTPUT (server â†’ client) for each TTS chunk:\n",
        "      { \"audio\": \"<base64 PCM16 mono @ 44.1k>\", \"alignment\": { ... } }\n",
        "    \"\"\"\n",
        "    await ws.accept()\n",
        "    lang_code = DEFAULT_LANG\n",
        "    voice = DEFAULT_VOICE\n",
        "    buf: list[str] = []\n",
        "\n",
        "    t_first_text_ns  = None   # when the first *real* text chunk arrives\n",
        "    t_first_audio_ns = None   # when we send the first audio frame\n",
        "    lat_printed = False\n",
        "\n",
        "    async def synth_and_stream(text: str):\n",
        "\n",
        "        nonlocal t_first_text_ns, t_first_audio_ns, lat_printed\n",
        "\n",
        "        if not text.strip():\n",
        "            return\n",
        "\n",
        "        pipe = get_pipeline(lang_code)\n",
        "\n",
        "        # learn source sample rate if exposed by pipeline\n",
        "        src_sr = getattr(pipe, \"sample_rate\", SRC_SR_DEFAULT)\n",
        "\n",
        "        if t_first_text_ns is None:\n",
        "            t_first_text_ns = perf_counter_ns()\n",
        "\n",
        "        try:\n",
        "            generator = pipe(text, voice=voice)\n",
        "            for gs, ps, audio in generator:\n",
        "\n",
        "                if not lat_printed:\n",
        "                    t_first_audio_ns = time.perf_counter_ns()\n",
        "                    dt_ms = (t_first_audio_ns - t_first_text_ns or t_first_audio_ns) / 1e6\n",
        "\n",
        "                    LAT.append(dt_ms)\n",
        "                    p50 = statistics.median(LAT)\n",
        "                    print(f\"[lat] first_textâ†’first_audio = {dt_ms:.1f} ms \" f\"(p50={p50:.1f} ms, n={len(LAT)})\")\n",
        "                    lat_printed = True\n",
        "\n",
        "\n",
        "\n",
        "                #log_audio(\"model_chunk\", audio)\n",
        "\n",
        "                # encode audio as raw PCM16 @ 44.1k (base64)\n",
        "                b64, n44 = encode_chunk_base64_pcm16_44k(audio, src_sr=src_sr)\n",
        "                chunk_ms = total_ms_from_samples(n44)\n",
        "\n",
        "                # build alignment from gs and chunk duration\n",
        "                alignment = build_alignment_from_gs(gs, chunk_ms)\n",
        "\n",
        "                # send EXACTLY the two required fields\n",
        "                await ws.send_text(json.dumps({\n",
        "                    \"audio\": b64,\n",
        "                    \"alignment\": alignment\n",
        "                }))\n",
        "\n",
        "                #print(f\"sent: {n44} samples @44.1k ({chunk_ms:.0f} ms), base64_len={len(b64)}, chars={len(alignment['chars'])}\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            # optional: log error; spec has no error packet for audio chunks\n",
        "            print(\"TTS error:\", e)\n",
        "        finally:\n",
        "            # Ready to measure the next utterance on the same socket\n",
        "            t_first_text_ns  = None\n",
        "            t_first_audio_ns = None\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            raw = await ws.receive_text()\n",
        "            try:\n",
        "                msg = json.loads(raw)\n",
        "            except Exception:\n",
        "                # ignore bad JSON\n",
        "                continue\n",
        "\n",
        "\n",
        "            text = msg.get(\"text\", \"\")\n",
        "            flush = bool(msg.get(\"flush\", False))\n",
        "\n",
        "\n",
        "\n",
        "            # first priming chunk: \" \"\n",
        "            if text == \" \" and not flush and not buf:\n",
        "                buf.append(text)\n",
        "                continue\n",
        "\n",
        "\n",
        "            # accumulate non-empty, non-priming text\n",
        "            if text and text != \" \":\n",
        "                buf.append(text)\n",
        "\n",
        "            # flush â†’ synthesize buffered text, keep socket open\n",
        "            if flush:\n",
        "                text_to_speak = \"\".join(buf)\n",
        "                buf.clear()\n",
        "                await synth_and_stream(text_to_speak)\n",
        "                continue\n",
        "\n",
        "            # final empty chunk (no flush) â†’ close session\n",
        "            if text == \"\" and not flush:\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "    except WebSocketDisconnect:\n",
        "        pass\n",
        "\n"
      ],
      "metadata": {
        "id": "2hYnIpBrg8dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def warm_tts():\n",
        "    pipe = get_pipeline(DEFAULT_LANG)\n",
        "    _ = getattr(pipe, \"sample_rate\", SRC_SR_DEFAULT)\n",
        "    try:\n",
        "        gen = pipe(\"warmup.\", voice=DEFAULT_VOICE)\n",
        "        next(iter(gen))   # force first yield\n",
        "    except StopIteration:\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        print(\"warmup error:\", e)\n",
        "\n",
        "# Call once after defining app (before starting uvicorn):\n",
        "warm_tts()\n"
      ],
      "metadata": {
        "id": "Od4PEdO3g-mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start server in background\n",
        "import os, time, threading, uvicorn\n",
        "\n",
        "def _run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"warning\")\n",
        "\n",
        "thr = threading.Thread(target=_run, daemon=True)\n",
        "thr.start()\n",
        "time.sleep(2)\n",
        "print(\"âœ… Spec-compliant WS running at ws://127.0.0.1:8000/ws (tunnel wss://â€¦/ws)\")\n"
      ],
      "metadata": {
        "id": "6Ax23gOPhAEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt -yq install cloudflared || true\n",
        "\n",
        "import os, stat, urllib.request\n",
        "if os.system(\"cloudflared --version > /dev/null 2>&1\") != 0:\n",
        "    url = \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\"\n",
        "    urllib.request.urlretrieve(url, \"/usr/local/bin/cloudflared\")\n",
        "    os.chmod(\"/usr/local/bin/cloudflared\", os.stat(\"/usr/local/bin/cloudflared\").st_mode | stat.S_IEXEC)\n",
        "\n",
        "print(\"ðŸš€ Starting tunnel; keep this cell running while testing.\")\n",
        "!cloudflared tunnel --url http://127.0.0.1:8000 --no-autoupdate"
      ],
      "metadata": {
        "id": "SwtRdN-zhBxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}